ğŸš€ Smart Supply Chain Analytics Platform
ğŸ“Œ Project Overview

This project is an end-to-end Data Engineering pipeline built to simulate a real-world Supply Chain Analytics system. It processes streaming order data, applies Medallion Architecture (Bronze â†’ Silver â†’ Gold), orchestrates workflows using Airflow, and visualizes KPIs using Power BI.

The goal is to demonstrate practical experience with modern data engineering tools and real-world pipeline design.

ğŸ—ï¸ Architecture
Data Generation (CSV)
        â†“
Kafka Producer
        â†“
Kafka Topic (Streaming Orders)
        â†“
Kafka Consumer â†’ Bronze Layer (Raw Data)
        â†“
Silver Layer (Cleaned & Transformed Data)
        â†“
Gold Layer (Aggregated Business Metrics)
        â†“
Airflow (Pipeline Orchestration)
        â†“
Power BI (Business Dashboard)

ğŸ› ï¸ Tech Stack

Python

Apache Kafka

Apache Airflow

Medallion Architecture (Bronze, Silver, Gold)

Power BI

Git & GitHub

Ubuntu (Linux environment)

ğŸ“‚ Project Structure
SUPPLY_CHAIN_PROJECT/
â”‚
â”œâ”€â”€ Data_generation/
â”œâ”€â”€ kafka_producer/
â”œâ”€â”€ kafka_consumer/
â”œâ”€â”€ airflow_dags/
â”‚   â”œâ”€â”€ bronze_dag.py
â”‚   â”œâ”€â”€ silver_dag.py
â”‚   â”œâ”€â”€ gold_dag.py
â”‚   â””â”€â”€ master_pipeline_dag.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ silver/
â”‚   â””â”€â”€ gold/
â”‚
â””â”€â”€ README.md

ğŸ”„ Pipeline Explanation
ğŸ¥‰ Bronze Layer

Ingests raw Kafka order data

Stores unprocessed data

Acts as single source of truth

ğŸ¥ˆ Silver Layer

Cleans data

Handles null values

Standardizes formats

Prepares structured dataset

ğŸ¥‡ Gold Layer

Creates business-ready aggregations

Revenue by Product

Revenue by Warehouse

Orders by Status

ğŸ¯ Airflow Orchestration

Airflow is used to:

Automate execution of Bronze â†’ Silver â†’ Gold

Maintain task dependency

Retry on failure

Monitor pipeline health

Schedule daily execution

Without Airflow:

Manual script execution required

No automation

No monitoring

No retry logic

ğŸ“Š Power BI Dashboard

Built dashboards showing:

Revenue by Product

Revenue by Warehouse

Order Status Distribution

Total Units Sold

KPI Cards for Revenue & Orders

ğŸ§  Key Challenges & Learnings

Kafka offset handling issues

Authentication failures

Airflow environment conflicts

Python version compatibility

Folder structure confusion in Linux

Resolved using:

Proper environment isolation (venv)

Correct DAG folder configuration

Clear architecture separation

Step-by-step debugging

ğŸš€ How to Run

Activate virtual environment

Start Kafka

Run producer & consumer

Start Airflow:

airflow webserver -p 8080
airflow scheduler


Trigger Master DAG

Connect Power BI to Gold layer

ğŸ”® Future Enhancements

Add FastAPI for external client access

Deploy on Cloud (Azure / AWS)

Use Docker for full containerization

CI/CD Integration

Data Quality Checks


ARCHITECTURE
------------

<img width="1844" height="1005" alt="image" src="https://github.com/user-attachments/assets/15a379bb-c495-49ab-acf3-e4a48a473270" />


ğŸ‘¨â€ğŸ’» Author

Sathwik Kotian
Data Engineering Enthusiast
